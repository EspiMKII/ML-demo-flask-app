# -*- coding: utf-8 -*-
"""ML - Regression Simplified.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QWXohSzfO5Qs9XPxbUmHmRf8pKWq5nzw

# Stock market predictions - Linear Regression and Support Vector Regression  

This notebook aims to predict the stock market close value after `n` days, using machine learning regression models:
- Linear Regression
- Ridge Regression
- Lasso Regression
- Support Vector Regression

The dataset used in this project are GOOGL and GE stock values from [Huge Stock Market Dataset](https://www.kaggle.com/datasets/borismarjanovic/price-volume-data-for-all-us-stocks-etfs).

# Preprocessing

## Import modules

Requirements:


numpy==2.0.2  
pandas==2.2.2  
matplotlib==3.10.0  
statsmodels==0.14.4  
sklearn==1.6.1  
seaborn==0.13.2
"""

# !git clone https://github.com/Tatsnien/ML-project.git

# Commented out IPython magic to ensure Python compatibility.
# %cd ML-project

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
from sklearn.compose import TransformedTargetRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.svm import SVR
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV, KFold
from sklearn.metrics import root_mean_squared_error, mean_absolute_percentage_error, r2_score
from typing import Literal
from utils import *
import pickle as pkl
import os

sns.set_theme()

"""## Import datasets

First, we import 2 datasets [Stocks/googl.us.txt](https://github.com/Tatsnien/ML-project/blob/main/googl.us.txt?raw=true) and [Stocks/ge.us.txt](https://github.com/Tatsnien/ML-project/blob/main/ge.us.txt?raw=true) from the [Huge Stock Market Dataset](https://www.kaggle.com/datasets/borismarjanovic/price-volume-data-for-all-us-stocks-etfs).
"""

gg_df = pd.read_csv('https://github.com/Tatsnien/ML-project/blob/main/googl.us.txt?raw=true',
                 index_col=0,
                 parse_dates=True).drop(columns=['OpenInt'])
gg_df.head()

gg_df['Close'].plot(title='GOOG Stock Price', figsize=(10, 5))
plt.xlabel('Date')

gg_df.info()

ge_df = pd.read_csv('https://github.com/Tatsnien/ML-project/blob/main/ge.us.txt?raw=true',
                 index_col=0,
                 parse_dates=True).drop(columns=['OpenInt'])
ge_df.head()

ge_df['Close'].plot(title='GE Stock Price', figsize=(10, 5))
plt.xlabel('Date')

ge_df.info()

"""## Feature selection

In this notebook, close values are selected to be the features due to its high autocorrelation nature.
"""

gg_acf = sm.tsa.acf(gg_df['Close'], nlags=20)
ge_acf = sm.tsa.acf(ge_df['Close'], nlags=20)

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(range(1, 21), gg_acf[1:])
plt.title('ACF for GOOGL Stock Price')
plt.xlabel('Lag')
plt.ylabel('Autocorrelation')
plt.xticks(range(1, 21))

plt.subplot(1, 2, 2)
plt.plot(range(1, 21), ge_acf[1:])
plt.title('ACF for GE Stock Price')
plt.xlabel('Lag')
plt.ylabel('Autocorrelation')
plt.xticks(range(1, 21))

plt.tight_layout()
plt.show()

"""The problem is, how many lags (window size) is sufficient for the model? The below graphs show the RMSE score vs window size, using simple Linear Regression model with 80-20 split.

Overall, RMSE follows an upward trend when the window size increases, but in general the window size doesn't affect much on the result. Window size = 1 is adequate for the prediction and reduces the computing complexity of the model. Thus, in the below implements, we will set window size = 1.
"""

from IPython.display import Image
Image(filename='image/GOOGL (5-day prediction, 80-20 split) - RMSE vs Window size.png',width=500)

Image(filename='image/GOOGL (30-day prediction, 80-20 split) - RMSE vs Window size.png',width=500)

Image(filename='image/GE (5-day prediction, 80-20 split) - RMSE vs Window size.png',width=500)

Image(filename='image/GE (30-day prediction, 80-20 split) - RMSE vs Window size.png',width=500)

"""## Create datasets"""

gg_X_1, gg_y_1 = create_dataset(gg_df, window=1, predicted_interval=1)
gg_X_30, gg_y_30 = create_dataset(gg_df, window=1, predicted_interval=30)
ge_X_1, ge_y_1 = create_dataset(ge_df, window=1, predicted_interval=1)
ge_X_30, ge_y_30 = create_dataset(ge_df, window=1, predicted_interval=30)

"""Divide the dataset into a training set (80%) and a testing set (20%). The dataset's order is maintained."""

gg_X_1_train, gg_X_1_test, gg_y_1_train, gg_y_1_test = split_dataset(gg_X_1, gg_y_1)
gg_X_30_train, gg_X_30_test, gg_y_30_train, gg_y_30_test = split_dataset(gg_X_30, gg_y_30)
ge_X_1_train, ge_X_1_test, ge_y_1_train, ge_y_1_test = split_dataset(ge_X_1, ge_y_1)
ge_X_30_train, ge_X_30_test, ge_y_30_train, ge_y_30_test = split_dataset(ge_X_30, ge_y_30)

"""# Models

Implementations of models and save them to `ML-project` folder as `.pkl` files (sorry for the inconvenience, but choking into file organization is painful). You can retrieve those model using the following syntax:
```
with open(filename, 'rb') as f:
    model = pickle.load(f)
```

For example
```
with open("ge_lr_1.pkl", 'rb') as f:
    model = pickle.load(f)
```
Or in case the training process is too slow, I have saved them in `trained_models` folder, though maybe not up-to-date.
"""

from google.colab import drive
drive.mount('/content/drive')

"""### Linear Regression

GOOGL dataset, Linear Regression, window size = 1, predict 1 day ahead
"""

gg_lr_1 = LinearRegression()
gg_lr_1.fit(gg_X_1_train, gg_y_1_train)
gg_y_1_pred = gg_lr_1.predict(gg_X_1_test)
with open('gg_lr_1.pkl', 'wb') as f:
    pkl.dump(gg_lr_1, f)

"""GOOGL dataset, Linear Regression, window size = 1, predict 30 days ahead"""

gg_lr_30 = LinearRegression()
gg_lr_30.fit(gg_X_30_train, gg_y_30_train)
gg_y_30_pred = gg_lr_30.predict(gg_X_30_test)
with open('gg_lr_30.pkl', 'wb') as f:
    pkl.dump(gg_lr_30, f)

"""GE dataset, Linear Regression, window size = 1, predict 1 day ahead"""

ge_lr_1 = LinearRegression()
ge_lr_1.fit(ge_X_1_train, ge_y_1_train)
ge_y_1_pred = ge_lr_1.predict(ge_X_1_test)
with open('ge_lr_1.pkl', 'wb') as f:
    pkl.dump(ge_lr_1, f)

"""GE dataset, Linear Regression, window size = 1, predict 30 days ahead"""

ge_lr_30 = LinearRegression()
ge_lr_30.fit(ge_X_30_train, ge_y_30_train)
ge_y_30_pred = ge_lr_30.predict(ge_X_30_test)
with open('ge_lr_30.pkl', 'wb') as f:
    pkl.dump(ge_lr_30, f)

"""### Ridge Regression

For Ridge and Lasso Regression, `finetune_frame` is applied. In fact it is basically GridSearchCV of sklearn (a method which tries every combination of the parameters in the `param_grid` to find the set of parameters that maximizes the model performance, in particular, MSE score). GridSearchCV executes in a cross-validation manner, which means the dataset is split into `n` folds; at each run, 1 of them is chosen to be test set and the remained folds become train set.

This approach can not be applied for time series dataset, for which the future traits can be used to predict past values. Hence, the finetune_frame customizes the cross-validation to become Forward chaining cross-validation. ([see explanation below](##Forward-chaining-cross-validation-method))

GOOGL dataset, Ridge Regression, window size = 1, predict 1 day ahead
"""

gg_ridge_1 = finetune_frame(Ridge(), gg_X_1_train, gg_X_1_test, gg_y_1_train, gg_y_1_test, param_grid={
    'regressor__model__alpha': [0.0, 0.001, 0.01, 0.1],
    'regressor__model__solver': ['auto', 'saga', 'sparse_cg']
})
print(gg_ridge_1['GridSearch'].best_params_)
with open('gg_ridge_1.pkl', 'wb') as f:
    pkl.dump(gg_ridge_1['GridSearch'].best_estimator_, f)

"""GOOGL dataset, Ridge Regression, window size = 1, predict 30 days ahead"""

gg_ridge_30 = finetune_frame(Ridge(), gg_X_30_train, gg_X_30_test, gg_y_30_train, gg_y_30_test, param_grid={
    'regressor__model__alpha': [0.0, 0.001, 0.01, 0.1],
    'regressor__model__solver': ['auto', 'saga', 'sparse_cg']
})
print(gg_ridge_30['GridSearch'].best_params_)
with open('gg_ridge_30.pkl', 'wb') as f:
    pkl.dump(gg_ridge_30['GridSearch'].best_estimator_, f)

"""GE dataset, Ridge Regression, window size = 1, predict 1 day ahead"""

ge_ridge_1 = finetune_frame(Ridge(), ge_X_1_train, ge_X_1_test, ge_y_1_train, ge_y_1_test, param_grid={
    'regressor__model__alpha': [0.0, 0.001, 0.01, 0.1],
    'regressor__model__solver': ['auto', 'saga', 'sparse_cg']
})
print(ge_ridge_1['GridSearch'].best_params_)
with open('ge_ridge_1.pkl', 'wb') as f:
    pkl.dump(ge_ridge_1['GridSearch'].best_estimator_, f)

"""GE dataset, Ridge Regression, window size = 1, predict 30 days ahead"""

ge_ridge_30 = finetune_frame(Ridge(), ge_X_30_train, ge_X_30_test, ge_y_30_train, ge_y_30_test, param_grid={
    'regressor__model__alpha': [0.0, 0.001, 0.01, 0.1],
    'regressor__model__solver': ['auto', 'saga', 'sparse_cg']
})
print(ge_ridge_30['GridSearch'].best_params_)
with open('ge_ridge_30.pkl', 'wb') as f:
    pkl.dump(ge_ridge_30['GridSearch'].best_estimator_, f)

"""### Lasso Regression

GOOGL dataset, Lasso Regression, window size = 1, predict 1 day ahead
"""

gg_lasso_1 = finetune_frame(Lasso(), gg_X_1_train, gg_X_1_test, gg_y_1_train, gg_y_1_test, param_grid={
    'regressor__model__alpha': [0.0, 0.001, 0.01, 0.1]
})
print(gg_lasso_1['GridSearch'].best_params_)
with open('gg_lasso_1.pkl', 'wb') as f:
    pkl.dump(gg_lasso_1['GridSearch'].best_estimator_, f)

"""GOOGL dataset, Lasso Regression, window size = 1, predict 30 days ahead"""

gg_lasso_30 = finetune_frame(Lasso(), gg_X_30_train, gg_X_30_test, gg_y_30_train, gg_y_30_test, param_grid={
    'regressor__model__alpha': [0.0, 0.001, 0.01, 0.1]
})
print(gg_lasso_30['GridSearch'].best_params_)
with open('gg_lasso_30.pkl', 'wb') as f:
    pkl.dump(gg_lasso_30['GridSearch'].best_estimator_, f)

"""GE dataset, Lasso Regression, window size = 1, predict 1 day ahead"""

ge_lasso_1 = finetune_frame(Lasso(), ge_X_1_train, ge_X_1_test, ge_y_1_train, ge_y_1_test, param_grid={
    'regressor__model__alpha': [0.0, 0.001, 0.01, 0.1]
})
print(ge_lasso_1['GridSearch'].best_params_)
with open('ge_lasso_1.pkl', 'wb') as f:
    pkl.dump(ge_lasso_1['GridSearch'].best_estimator_, f)

"""GE dataset, Lasso Regression, window size = 1, predict 30 days ahead"""

ge_lasso_30 = finetune_frame(Lasso(), ge_X_30_train, ge_X_30_test, ge_y_30_train, ge_y_30_test, param_grid={
    'regressor__model__alpha': [0.0, 0.001, 0.01, 0.1]
})
print(ge_lasso_30['GridSearch'].best_params_)
with open('ge_lasso_30.pkl', 'wb') as f:
    pkl.dump(ge_lasso_30['GridSearch'].best_estimator_, f)

"""### Support Vector Regression"""

# svr_param_grid = {
#     'regressor__model__C': [10, 50, 100],
#     'regressor__model__kernel': ['linear', 'rbf', 'poly', 'sigmoid'],
#     'regressor__model__epsilon': [0.001, 0.01, 0.1],
#     'regressor__model__gamma': ['scale', 'auto']
# }

svr_param_grid = {
    'regressor__model__C': [10, 50, 100, 1000, 5000],
    'regressor__model__kernel': ['linear'],
    'regressor__model__epsilon': [0.0, 0.01, 0.1],
    'regressor__model__gamma': ['scale']
}

"""GOOGL dataset, Support Vector Regression, window size = 1, predict 1 day ahead

SVR RMSE: 10.5869, R^2: 0.9931

Coef: [[0.99933068]]  
MAPE: 0.9170%  
Max APE: 13.9873%  
sMAPE: 0.9193%  
Best params: {'regressor__model__C': 1000', regressor__model__epsilon': 0.01,  'regressor__model__gamma': 'scale', 'regressor__model__kernel': 'linear'}
"""

gg_svr_1 = finetune_frame(SVR(), gg_X_1_train, gg_X_1_test, gg_y_1_train, gg_y_1_test, param_grid=svr_param_grid, cv=5)
print(gg_svr_1['GridSearch'].best_params_)

"""GOOGL dataset, Support Vector Regression, window size = 1, predict 30 days ahead

SVR RMSE: 46.8890, R^2: 0.8639

Coef: [[0.98029655]]  
MAPE: 4.4103%  
Max APE: 21.8332%  
sMAPE: 4.5449%  
{'regressor__model__C': 1000, 'regressor__model__epsilon': 0.01, 'regressor__model__gamma': 'scale', 'regressor__model__kernel': 'linear'}
"""

gg_svr_30 = finetune_frame(SVR(), gg_X_30_train, gg_X_30_test, gg_y_30_train, gg_y_30_test, param_grid=svr_param_grid, cv=5)
print(gg_svr_30['GridSearch'].best_params_)

"""GE dataset, Support Vector Regression, window size = 1, predict 1 day ahead

SVR RMSE: 0.3364, R^2: 0.9974

Coef: [[0.99819392]]  
MAPE: 1.2013%  
Max APE: 16.2111%  
sMAPE: 1.1996%  
{'regressor__model__C': 100, 'regressor__model__epsilon': 0.1, 'regressor__model__gamma': 'scale', 'regressor__model__kernel': 'linear'}
"""

ge_svr_1 = finetune_frame(SVR(), ge_X_1_train.tail(1000), ge_X_1_test, ge_y_1_train.tail(1000), ge_y_1_test, param_grid=svr_param_grid, cv=5)
print(ge_svr_1['GridSearch'].best_params_)

with open('ge_svr_1.pkl', 'wb') as f:
    pkl.dump(ge_svr_1['GridSearch'].best_estimator_, f)

"""GE dataset, Support Vector Regression, window size = 1, predict 30 days ahead"""

ge_svr_30 = finetune_frame(SVR(), ge_X_30_train.tail(3000), ge_X_30_test, ge_y_30_train.tail(3000), ge_y_30_test, param_grid=svr_param_grid, cv=5)
print(ge_svr_30['GridSearch'].best_params_)

with open('ge_svr_30.pkl', 'wb') as f:
    pkl.dump(ge_svr_30['GridSearch'].best_estimator_, f)

"""# Evaluation

## Metrics

In this notebook, each model will be evaluated by 3 metrics:
- RMSE
- R^2
- MAPE

1. **Root Mean Squared Error ($RMSE$)**:

$$RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}$$

RMSE calculates the square root of the average of the squared differences between the actual and predicted values. Squaring the errors gives a higher weight to larger errors, and the square root brings the metric back to the original unit of the target variable, making it easier to interpret.

2. **R-Squared ($R^2$)**

$$R^2 = 1 - \frac{SS_{res}}{SS_{tot}} = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}$$

R-squared represents the proportion of the variance in the dependent variable that is predictable from the independent variable(s). It ranges from 0 to 1, where a higher value indicates that the model explains a larger portion of the variance in the target variable.

3. **Mean Absolute Percentage Error ($MAPE$)**

$$MAPE = \frac{1}{n} \sum_{i=1}^{n} \left| \frac{y_i - \hat{y}_i}{y_i} \right| \times 100\%$$

MAPE calculates the average of the absolute percentage differences between the actual and predicted values. It expresses the error as a percentage, making it easy to understand the relative size of the error.

## Holdout method

This method split the dataset into 2 separated parts: training set (80%) and testing set (20%). In this notebook, due to the time series nature of the stock dataset, the relative order of the dataset is maintained.
"""

from IPython.display import Image
Image(filename='image/traintest8020.png',width=500)

"""GOOGL dataset, Linear Regression, window size = 1, predict 1 day ahead"""

print(f'RMSE: {root_mean_squared_error(gg_y_1_test, gg_y_1_pred):.4f}')
print(f'R^2: {r2_score(gg_y_1_test, gg_y_1_pred):.4f}')
print(f'MAPE: {mean_absolute_percentage_error(gg_y_1_test, gg_y_1_pred) * 100:.4f}%')

"""GOOGL dataset, Linear Regression, window size = 1, predict 30 days ahead"""

print(f'RMSE: {root_mean_squared_error(gg_y_30_test, gg_y_30_pred):.4f}')
print(f'R^2: {r2_score(gg_y_30_test, gg_y_30_pred):.4f}')
print(f'MAPE: {mean_absolute_percentage_error(gg_y_30_test, gg_y_30_pred) * 100:.4f}%')

"""GE dataset, Linear Regression, window size = 1, predict 1 day ahead"""

print(f'RMSE: {root_mean_squared_error(ge_y_1_test, ge_y_1_pred):.4f}')
print(f'R^2: {r2_score(ge_y_1_test, ge_y_1_pred):.4f}')
print(f'MAPE: {mean_absolute_percentage_error(ge_y_1_test, ge_y_1_pred) * 100:.4f}%')

"""GE dataset, Linear Regression, window size = 1, predict 30 days ahead"""

print(f'RMSE: {root_mean_squared_error(ge_y_30_test, ge_y_30_pred):.4f}')
print(f'R^2: {r2_score(ge_y_30_test, ge_y_30_pred):.4f}')
print(f'MAPE: {mean_absolute_percentage_error(ge_y_30_test, ge_y_30_pred) * 100:.4f}%')

"""## Forward chaining cross-validation method

This method split the data set into `n` folds. In this notebook, due to the time series nature of the stock dataset, the relative order of the dataset is maintained. Each time, a fold is selected to be the testing set, and all folds before it becomes training set. The overall scores of this method is the average scores of all runs.
"""

Image(filename='image/chainforward.png',height=300)

"""GOOGL dataset, Linear Regression, window size = 1, predict 1 day ahead

## Plotting

GOOGL dataset, Linear Regression, window size = 1, predict 5 days ahead
"""

gg_compared_df_1 = pd.DataFrame({
    'True': gg_y_1_test,
    'Predicted': gg_y_1_pred
}, gg_y_1_test.index)
plt.figure(figsize=(10, 5))
sns.lineplot(x=gg_compared_df_1.index, y=gg_compared_df_1['True'], label='True Values')
sns.lineplot(x=gg_compared_df_1.index, y=gg_compared_df_1['Predicted'], label='Predicted Values')
plt.title(f'Linear Regression Predictions')
plt.xlabel('Sample Index')
plt.ylabel('Stock Price')
plt.legend()
plt.show()

"""GOOGL dataset, Linear Regression, window size = 1, predict 30 days ahead"""

gg_compared_df_30 = pd.DataFrame({
    'True': gg_y_30_test,
    'Predicted': gg_y_30_pred
}, gg_y_30_test.index)
plt.figure(figsize=(10, 5))
sns.lineplot(x=gg_compared_df_30.index, y=gg_compared_df_30['True'], label='True Values')
sns.lineplot(x=gg_compared_df_30.index, y=gg_compared_df_30['Predicted'], label='Predicted Values')
plt.title(f'Linear Regression Predictions')
plt.xlabel('Sample Index')
plt.ylabel('Stock Price')
plt.legend()
plt.show()

"""GE dataset, Linear Regression, window size = 1, predict 1 day ahead"""

ge_compared_df_1 = pd.DataFrame({
    'True': ge_y_1_test,
    'Predicted': ge_y_1_pred
}, ge_y_1_test.index)
plt.figure(figsize=(10, 5))
sns.lineplot(x=ge_compared_df_1.index, y=ge_compared_df_1['True'], label='True Values')
sns.lineplot(x=ge_compared_df_1.index, y=ge_compared_df_1['Predicted'], label='Predicted Values')
plt.title(f'Linear Regression Predictions')
plt.xlabel('Sample Index')
plt.ylabel('Stock Price')
plt.legend()
plt.show()

"""GE dataset, Linear Regression, window size = 1, predict 30 days ahead"""

ge_compared_df_30 = pd.DataFrame({
    'True': ge_y_30_test,
    'Predicted': ge_y_30_pred
}, ge_y_30_test.index)
plt.figure(figsize=(10, 5))
sns.lineplot(x=ge_compared_df_30.index, y=ge_compared_df_30['True'], label='True Values')
sns.lineplot(x=ge_compared_df_30.index, y=ge_compared_df_30['Predicted'], label='Predicted Values')
plt.title(f'Linear Regression Predictions')
plt.xlabel('Sample Index')
plt.ylabel('Stock Price')
plt.legend()
plt.show()

"""# Results

GOOGL dataset, window size = 1, predict 1 day ahead.

|Model|$RMSE$|$R^2$|$MAPE$|
|-|-|-|-|
|Linear Regression|10.5878|0.9931|0.9172%|
|Ridge Regression |10.5865|0.9931|0.9170%|
|Lasso Regression |10.5878|0.9931|0.9172%|
|Support Vector Regression|10.5869|0.9931|0.9170%|

GOOGL dataset, window size = 1, predict 30 days ahead.

|Model|$RMSE$|$R^2$|$MAPE$|
|-|-|-|-|
|Linear Regression|46.6429|0.8653|4.3869%|
|Ridge Regression |46.6534|0.8653|4.3879%|
|Lasso Regression |46.6429|0.8653|4.3869%|
|Support Vector Regression|46.8890|0.8639|4.4103%|

GE dataset, window size = 1, predict 1 day ahead.

|Model|$RMSE$|$R^2$|$MAPE$|
|-|-|-|-|
|Linear Regression|0.3364|0.9974|1.2023%|
|Ridge Regression |0.3364|0.9974|1.2023%|
|Lasso Regression |0.3364|0.9974|1.2023%|
|Support Vector Regression|0.3364|0.9974|1.2013%|

GE dataset, window size = 1, predict 30 days ahead.

|Model|$RMSE$|$R^2$|$MAPE$|
|-|-|-|-|
|Linear Regression|1.4786|0.9508|6.2042%|
|Ridge Regression |1.4786|0.9508|6.2041%|
|Lasso Regression |1.4699|0.9513|6.1709%|
|Support Vector Regression|1.6330|0.9399|7.1193%|
"""